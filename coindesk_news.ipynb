{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from lxml import html, etree\n",
    "import time\n",
    "import json\n",
    "import datetime\n",
    "\n",
    "PROXIES = {\n",
    " ## 'http': 'http://VPN4726:@ar.finevpn.org',\n",
    " ## 'https': 'https://VPN4726:@ar.finevpn.org',\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page 387 parsed\n",
      "page 388 parsed\n",
      "page 389 parsed\n",
      "page 390 parsed\n",
      "page 391 parsed\n",
      "page 392 parsed\n",
      "page 393 parsed\n",
      "page 394 parsed\n",
      "page 395 parsed\n",
      "page 396 parsed\n",
      "page 397 parsed\n",
      "page 398 parsed\n",
      "page 399 parsed\n",
      "page 400 parsed\n",
      "page 401 parsed\n",
      "page 402 parsed\n",
      "page 403 parsed\n",
      "page 404 parsed\n",
      "page 405 parsed\n",
      "page 406 parsed\n",
      "page 407 parsed\n",
      "page 408 parsed\n",
      "page 409 parsed\n",
      "page 410 parsed\n",
      "page 411 parsed\n",
      "page 412 parsed\n",
      "page 413 parsed\n",
      "page 414 parsed\n",
      "page 415 parsed\n",
      "page 416 parsed\n",
      "page 417 parsed\n",
      "page 418 parsed\n",
      "page 419 parsed\n",
      "page 420 parsed\n",
      "page 421 parsed\n",
      "page 422 parsed\n",
      "page 423 parsed\n",
      "error reading text from page:  https://www.coindesk.com/legal-liability-dao/\n",
      "page 424 parsed\n",
      "page 425 parsed\n",
      "page 426 parsed\n",
      "page 427 parsed\n",
      "page 428 parsed\n",
      "error reading text from page:  https://www.coindesk.com/building-better-bitcoin-fee-market/\n",
      "page 429 parsed\n",
      "page 430 parsed\n",
      "page 431 parsed\n",
      "page 432 parsed\n",
      "page 433 parsed\n",
      "page 434 parsed\n",
      "page 435 parsed\n",
      "page 436 parsed\n",
      "page 437 parsed\n",
      "page 438 parsed\n",
      "page 439 parsed\n",
      "page 440 parsed\n",
      "page 441 parsed\n",
      "page 442 parsed\n",
      "page 443 parsed\n",
      "page 444 parsed\n",
      "page 445 parsed\n",
      "page 446 parsed\n",
      "page 447 parsed\n",
      "page 448 parsed\n",
      "error reading text from page:  https://www.coindesk.com/australian-government-seeks-end-to-double-taxation-of-bitcoin/\n",
      "page 449 parsed\n",
      "page 450 parsed\n",
      "page 451 parsed\n",
      "page 452 parsed\n",
      "page 453 parsed\n",
      "page 454 parsed\n",
      "page 455 parsed\n",
      "page 456 parsed\n",
      "page 457 parsed\n",
      "page 458 parsed\n",
      "page 459 parsed\n",
      "page 460 parsed\n"
     ]
    }
   ],
   "source": [
    "## http://docs.python-guide.org/en/latest/scenarios/scrape/\n",
    "##\n",
    "\n",
    "class news_coindesk_parser():\n",
    "    def __init__(self):\n",
    "        ## self.link = 'https://www.coindesk.com/page/'\n",
    "        self.save_dir = \"news_coindesk/\"\n",
    "    \n",
    "    def read_article_text(self,article_href, verbose=False):\n",
    "        article_page = requests.get(article_href, proxies=PROXIES)\n",
    "        article_html = html.fromstring(article_page.content)\n",
    "        \n",
    "        try:\n",
    "            article_text = article_html.xpath('//div[@class=\"single-content\"]')[0]\n",
    "            text = etree.tostring(article_text).decode(\"utf-8\") \n",
    "        except:\n",
    "            print (\"error reading text from page: \",article_href)\n",
    "            text = \"\"\n",
    "\n",
    "        text = re.sub(\"<em>The leader in blockchain news.*?</em>\",\"\",text)\n",
    "        if verbose: print (text)\n",
    "        return text\n",
    "    \n",
    "    def clean_text (self,article_text):\n",
    "        article_text = re.sub(\"<script>.*?</script>\",\"\",article_text)\n",
    "        article_text = re.sub(\"<.*?>\",\"\",article_text)\n",
    "        article_text = re.sub(\"&#8217;\",\"'\",article_text)\n",
    "        article_text = re.sub(\"&#[0-9]+;|\\n\",\" \",article_text)\n",
    "        article_text = re.sub(\" {1,}\",\" \",article_text)\n",
    "\n",
    "        return article_text\n",
    "\n",
    "    def parse_page(self,page_num, verbose = True):\n",
    "\n",
    "        page_link = \"https://www.coindesk.com/page/\" + str(page_num) + \"/\"\n",
    "        r = requests.get(page_link, proxies = PROXIES)\n",
    "        \n",
    "        articles_html = html.fromstring(r.content)\n",
    "        articles_html = articles_html.xpath('//div[@id=\"content\"]')[0]\n",
    "        articles_html = articles_html.xpath('.//div[@class=\"article medium bordered\"]')\n",
    "\n",
    "        if len(articles_html) == 0:\n",
    "            print (\"error reading page \",page_link)\n",
    "\n",
    "        for i_article in articles_html:\n",
    "\n",
    "            ## parsing date\n",
    "            ##\n",
    "            art_time = i_article.xpath('.//time/@datetime')[0]\n",
    "            art_date = art_time[0:10]    \n",
    "\n",
    "            art_title = i_article.xpath('.//div[@class=\"post-info\"]/h3')[0]\n",
    "            art_title = etree.tostring(art_title).decode('utf-8')\n",
    "            art_title = self.clean_text(art_title)\n",
    "            \n",
    "            try:\n",
    "                art_cont = i_article.xpath('.//div[@class=\"post-info\"]/p')[1]\n",
    "                art_cont = etree.tostring(art_cont).decode('utf-8')\n",
    "                art_cont = self.clean_text(art_cont)\n",
    "            except:\n",
    "                art_cont = \"\"\n",
    "                \n",
    "            art_href =  i_article.xpath('.//div[@class=\"post-info\"]/h3/a/@href')[0]\n",
    "\n",
    "            if verbose: print (art_date,art_time, art_title, art_cont, art_href)\n",
    "\n",
    "            ## read article text\n",
    "            article_text = self.read_article_text(art_href,verbose=False)\n",
    "            article_text = self.clean_text(article_text)\n",
    "\n",
    "            \n",
    "            ## saving article\n",
    "            fn = re.sub(\"[^a-zA-Z0-9 ]\",\"\",art_title[0:20])\n",
    "            file_name = self.save_dir + art_date + \"_\" + 'p_' + '{num:03d}'.format(num=page_num) + \"_\" + fn + \".txt\"\n",
    "            if verbose: print ('FILE NAME: ',file_name)\n",
    "            f = open(file_name,'w', encoding = 'utf-8')\n",
    "            f.write(art_title + \"\\n\")\n",
    "            f.write(art_time + \"\\n\")\n",
    "            f.write(\"<brief>\" + art_cont + \"</brief>\\n\")\n",
    "            f.write(article_text)\n",
    "            f.close()\n",
    "        print (\"page \" + str(page_num) + \" parsed\")\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "bc_parser = news_coindesk_parser()\n",
    "\n",
    "for i in range(387,900):\n",
    "    bc_parser.parse_page(i,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
