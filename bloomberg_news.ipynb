{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from lxml import html, etree\n",
    "import time\n",
    "\n",
    "\n",
    "PROXIES = {\n",
    "  'http': 'http://VPN4726:24ZokIf2ut@ar.finevpn.org',\n",
    "  'https': 'https://VPN4726:24ZokIf2ut@ar.finevpn.org',\n",
    "}\n",
    "\n",
    "PROXIES ={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page 202 parsed\n",
      "page 203 parsed\n",
      "page 204 parsed\n",
      "page 205 parsed\n",
      "page 206 parsed\n",
      "page 207 parsed\n",
      "page 208 parsed\n",
      "page 209 parsed\n",
      "page 210 parsed\n",
      "page 211 parsed\n",
      "page 212 parsed\n",
      "page not found  https://www.bloomberg.com/news/articles/2017-05-15/new-wave-of-ransom-threats-seen-in-unprecedented-global-attack\n",
      "page 213 parsed\n",
      "page 214 parsed\n",
      "page 215 parsed\n",
      "page 216 parsed\n",
      "page 217 parsed\n",
      "page 218 parsed\n",
      "page 219 parsed\n",
      "page 220 parsed\n",
      "page 221 parsed\n",
      "page 222 parsed\n",
      "page 223 parsed\n",
      "page 224 parsed\n",
      "page 225 parsed\n",
      "page 226 parsed\n",
      "page 227 parsed\n",
      "page 228 parsed\n",
      "page 229 parsed\n",
      "page 230 parsed\n",
      "page 231 parsed\n",
      "page 232 parsed\n",
      "page 233 parsed\n",
      "page 234 parsed\n",
      "page 235 parsed\n",
      "page 236 parsed\n",
      "page 237 parsed\n",
      "page 238 parsed\n",
      "page 239 parsed\n",
      "page 240 parsed\n",
      "page 241 parsed\n",
      "page 242 parsed\n",
      "page 243 parsed\n",
      "page 244 parsed\n",
      "page 245 parsed\n",
      "page 246 parsed\n",
      "page 247 parsed\n",
      "page 248 parsed\n",
      "page 249 parsed\n",
      "page 250 parsed\n",
      "page 251 parsed\n",
      "page 252 parsed\n",
      "error reading page  https://www.bloomberg.com/news/articles/2016-01-07/the-return-of-bitcoin-mining\n",
      "page 253 parsed\n",
      "page 254 parsed\n",
      "page 255 parsed\n",
      "page 256 parsed\n",
      "page 257 parsed\n",
      "page 258 parsed\n",
      "page not found  https://www.bloomberg.com/news/articles/2014-07-25/blockchain-info-planning-to-roll-out-wallet-on-app-store\n",
      "page not found  https://www.bloomberg.com/news/articles/2014-07-17/bitcoins-can-t-shake-bubble-image-in-poll-after-45-drop\n",
      "page not found  https://www.bloombergview.com/articles/2014-07-17/trust-will-kill-bitcoin\n",
      "page not found  https://www.bloomberg.com/news/articles/2014-06-30/etf-halftime-report-2013-s-losers-lead-vanguard-hauls-it-in\n",
      "page not found  https://www.bloombergview.com/articles/2014-02-27/i-still-believe-in-bitcoin\n",
      "page not found  https://www.bloombergview.com/articles/2014-02-25/weil-on-finance-credit-suisse-s-tough-day\n",
      "page not found  https://www.bloomberg.com/news/articles/2014-02-19/israel-s-central-bank-warns-on-bitcoin-saying-its-open-to-fraud\n",
      "page not found  https://www.bloomberg.com/news/articles/2014-02-10/bitcoin-exchange-mt-gox-says-users-can-withdraw-cash-as-normal\n",
      "page 259 parsed\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-c9445d7f7d0d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m202\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m400\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 117\u001b[1;33m     \u001b[0mbc_parser\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparse_page\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-4-c9445d7f7d0d>\u001b[0m in \u001b[0;36mparse_page\u001b[1;34m(self, page_num, verbose)\u001b[0m\n\u001b[0;32m     50\u001b[0m         \u001b[0mnews\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpage_html\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'//div[@class=\"search-result-items\"]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[1;31m## print (news)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[0marticles\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnews\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxpath\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.//div[@class=\"search-result-story__container\"]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m         \u001b[1;31m# print (articles)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[1;31m## for debugging\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "## http://docs.python-guide.org/en/latest/scenarios/scrape/\n",
    "##\n",
    "\n",
    "class news_bloomberg_parser():\n",
    "    def __init__(self):\n",
    "        self.link = 'https://www.bloomberg.com/search?query=bitcoin&endTime=2018-03-29T11:05:45.378Z&page='\n",
    "        self.save_dir = \"news_bloomberg/\"\n",
    "    \n",
    "    def read_article_text(self,article_href):\n",
    "        key_done = 0\n",
    "        while key_done <3:\n",
    "            try:\n",
    "                article_page = requests.get(article_href, proxies=PROXIES)\n",
    "                key_done = 3\n",
    "            except:\n",
    "                print ('error reading page ',article_href)\n",
    "                time.sleep(20)\n",
    "                key_done +=1\n",
    "                if key_done ==3:\n",
    "                    return \"\"\n",
    "        article_html = html.fromstring(article_page.content)\n",
    "        try:\n",
    "            article_text = article_html.xpath('//article/*/section[@class=\"main-column\"]')[0]\n",
    "        except:\n",
    "            print ('page not found ',article_href)\n",
    "            return \"\"\n",
    "        article_text = article_text.xpath('.//div[@class=\"body-copy fence-body\"]')[0]\n",
    "        text = etree.tostring(article_text).decode(\"utf-8\") \n",
    "        text = re.sub(\"<figure.*?</figure>\",\"\",text)\n",
    "        text = re.findall(\"<p>.*?</p>\",text)\n",
    "        text = \"\".join([x for x in text])\n",
    "        return text\n",
    "    \n",
    "    def clean_text (self,article_text):\n",
    "        article_text = re.sub(\"<.*?>\",\"\",article_text)\n",
    "        article_text = re.sub(\"&#8217;\",\"'\",article_text)\n",
    "        article_text = re.sub(\"&#[0-9]+;|\\n\",\" \",article_text)\n",
    "        article_text = re.sub(\" {1,}\",\" \",article_text)\n",
    "\n",
    "        return article_text\n",
    "\n",
    "    def parse_page(self,page_num, verbose = True):\n",
    "        page_link = self.link + str(page_num)\n",
    "        \n",
    "        if verbose: print (page_link)\n",
    "        \n",
    "        page = requests.get(page_link, proxies=PROXIES)\n",
    "        page_html = html.fromstring(page.content)\n",
    "        \n",
    "        news = page_html.xpath('//div[@class=\"search-result-items\"]')\n",
    "        ## print (news)\n",
    "        articles = news[0].xpath('.//div[@class=\"search-result-story__container\"]')\n",
    "        # print (articles)\n",
    "        ## for debugging\n",
    "        self.page = page\n",
    "        self.page_html = page_html\n",
    "        self.articles = articles \n",
    "        if verbose: print ('read page ' + str(page_num))\n",
    "        \n",
    "        for i_article in articles:\n",
    "            article_name = i_article.xpath('.//h1[@class=\"search-result-story__headline\"]/a')[0]\n",
    "            article_name = etree.tostring(article_name).decode(\"utf-8\") \n",
    "            article_name = self.clean_text(article_name)\n",
    "            if verbose: print (article_name)\n",
    "            \n",
    "            article_time = i_article.xpath('.//time[@class=\"published-at\"]/@datetime')[0]\n",
    "            article_date = article_time[0:10]\n",
    "            if verbose: print (article_time)\n",
    "\n",
    "            article_href = i_article.xpath('.//h1[@class=\"search-result-story__headline\"]/a/@href')[0]\n",
    "            if verbose: print (article_href)\n",
    "\n",
    "            article_content = i_article.xpath('.//div[@class=\"search-result-story__body\"]')[0]\n",
    "            article_content = etree.tostring(article_content).decode(\"utf-8\") \n",
    "            article_content = self.clean_text(article_content)\n",
    "            if verbose: print (article_content)\n",
    "            \n",
    "            if len(re.findall('video',article_href))>0:\n",
    "                article_text = \"\"\n",
    "                article_c_type = 'video'\n",
    "            elif len(re.findall('bloombergview',article_href))>0:\n",
    "                article_text = self.read_article_text(article_href)\n",
    "                article_c_type = 'view'\n",
    "            elif len(re.findall('news/audio',article_href))>0:\n",
    "                article_text = \"\"\n",
    "                article_c_type = 'audio'\n",
    "            elif len(re.findall('news/features',article_href))>0:\n",
    "                article_text = \"\"  ## will do this part later\n",
    "                article_c_type = 'feature'\n",
    "            elif len(re.findall('news/photo-essays',article_href))>0:\n",
    "                article_text = \"\"  ## will do this part later\n",
    "                article_c_type = 'photo-essay'\n",
    "            else:\n",
    "                article_text = self.read_article_text(article_href)\n",
    "                article_c_type = 'news'\n",
    "\n",
    "            ## cleaning article from special symbols\n",
    "            article_text = self.clean_text(article_text)\n",
    "                        \n",
    "            ## saving article\n",
    "            fn = re.sub(\"[^a-zA-Z0-9 ]\",\"\",article_name[0:20])\n",
    "            file_name = self.save_dir + article_date + \"_\" + 'p_' + '{num:03d}'.format(num=page_num) + \"_\" + fn + \".txt\"\n",
    "            if verbose: print (file_name)\n",
    "            f = open(file_name,'w', encoding = 'utf-8')\n",
    "            f.write(article_name + \"\\n\")\n",
    "            f.write(article_time + \"\\n\")\n",
    "            f.write(\"<brief>\" + article_content + \"</brief>\\n\")\n",
    "            f.write(\"<content>\" + article_c_type + \"</content>\\n\")\n",
    "            f.write(article_text)\n",
    "            f.close()\n",
    "        print (\"page \" + str(page_num) + \" parsed\")\n",
    "\n",
    "            \n",
    "bc_parser = news_bloomberg_parser()\n",
    "\n",
    "for i in range(202,400):\n",
    "    bc_parser.parse_page(i,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
