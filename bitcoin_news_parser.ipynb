{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from lxml import html, etree\n",
    "\n",
    "## https://news.bitcoin.com/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page 1 parsed\n",
      "page 2 parsed\n",
      "page 3 parsed\n",
      "page 4 parsed\n",
      "page 5 parsed\n",
      "page 6 parsed\n",
      "page 7 parsed\n",
      "page 8 parsed\n",
      "page 9 parsed\n",
      "page 10 parsed\n",
      "page 11 parsed\n",
      "page 12 parsed\n",
      "page 13 parsed\n",
      "page 14 parsed\n",
      "page 15 parsed\n",
      "page 16 parsed\n",
      "page 17 parsed\n",
      "page 18 parsed\n",
      "page 19 parsed\n",
      "page 20 parsed\n",
      "page 21 parsed\n"
     ]
    }
   ],
   "source": [
    "## http://docs.python-guide.org/en/latest/scenarios/scrape/\n",
    "##\n",
    "\n",
    "class news_bitcoin_parser():\n",
    "    def __init__(self):\n",
    "        self.link = 'https://news.bitcoin.com/'\n",
    "        self.save_dir = \"news_bitcoin/\"\n",
    "    \n",
    "    def read_article_text(self,article_href):\n",
    "        article_page = requests.get(article_href)\n",
    "        article_html = html.fromstring(article_page.content)\n",
    "        article_content = article_html.xpath('//div[@class=\"td-post-content\"]')\n",
    "        text = etree.tostring(article_content[0])\n",
    "        text = text.decode(\"utf-8\")  \n",
    "        return text\n",
    "    \n",
    "    def clean_text (self,article_text):\n",
    "        article_text = re.sub(\"<.*?>\",\"\",article_text)\n",
    "        article_text = re.sub(\"&#[0-9]+;|\\n\",\" \",article_text)\n",
    "        article_text = re.sub(\" {1,}\",\" \",article_text)\n",
    "\n",
    "        return article_text\n",
    "\n",
    "    def parse_page(self,page_num, verbose = True):\n",
    "        page_link = self.link\n",
    "        if page_num>1:\n",
    "            page_link = self.link + \"/page/\" + str(page_num)\n",
    "        if page_num<=0:\n",
    "            return 0\n",
    "        page = requests.get(page_link)\n",
    "        page_html = html.fromstring(page.content)\n",
    "        \n",
    "        news = page_html.xpath('//div[@class=\"td-container td-pb-article-list\"]')\n",
    "        articles = news[0].xpath('.//div[@class=\"item-details\"]')\n",
    "\n",
    "        ## for debugging\n",
    "        self.page = page\n",
    "        self.page_html = page_html\n",
    "        self.articles = articles \n",
    "        if verbose: print ('read page ' + str(page_num))\n",
    "        \n",
    "        for i_article in articles:\n",
    "            article_name = i_article.xpath(\".//a/@title\")[0]\n",
    "            article_time = i_article.xpath(\".//time/@datetime\")[0]\n",
    "            article_date = article_time[0:10]\n",
    "            article_href = i_article.xpath(\".//a/@href\")[0]\n",
    "            article_text = self.read_article_text(article_href)\n",
    "            \n",
    "            ## cleaning article from special symbols\n",
    "            article_text = self.clean_text(article_text)\n",
    "                        \n",
    "            ## saving article\n",
    "            fn = re.sub(\"[^a-zA-Z0-9 ]\",\"\",article_name[0:20])\n",
    "            file_name = self.save_dir + article_date + \"_\" + 'p_' + '{num:03d}'.format(num=page_num) + \"_\" + fn + \".txt\"\n",
    "            if verbose: print (file_name)\n",
    "            f = open(file_name,'w', encoding = 'utf-8')\n",
    "            f.write(article_name + \"\\n\")\n",
    "            f.write(article_time+ \"\\n\")\n",
    "            f.write(article_text)\n",
    "            f.close()\n",
    "        print (\"page \" + str(page_num) + \" parsed\")\n",
    "\n",
    "            \n",
    "bc_parser = news_bitcoin_parser()\n",
    "\n",
    "for i in range(1,619):\n",
    "    bc_parser.parse_page(i,verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
